{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## __Lab 8 Assignment__\n",
    "## __Balbhadra Prajapati - 8873745__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing libraries\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the Data\n",
    "* Here we will use [tensorflow.keras.datasets](https://keras.io/api/datasets/) as our data repository. It provides API access to a collection of a few toy datasets (in numpy format) that can be used to train and test simple models.\n",
    "* [MNIST](https://keras.io/api/datasets/mnist/) is a dataset of 60,000 28x28 grayscale images of the 10 digits (0-9), along with a test set of 10,000 images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Fashion MNIST dataset\n",
    "fashion_mnist = keras.datasets.fashion_mnist\n",
    "(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image DType: <class 'numpy.ndarray'>\n",
      "Image Element DType: <class 'numpy.uint8'>\n",
      "Label Element DType: <class 'numpy.uint8'>\n",
      "**Shapes:**\n",
      "Train Data:\n",
      "Images: (60000, 28, 28)\n",
      "Labels: (60000,)\n",
      "Test Data:\n",
      "Images: (10000, 28, 28)\n",
      "Labels: (10000,)\n",
      "Image Data Range:\n",
      "Min: 0\n",
      "Max: 255\n"
     ]
    }
   ],
   "source": [
    "print(f'Image DType: {type(train_images)}')\n",
    "print(f'Image Element DType: {type(train_images[0,0,0])}')\n",
    "print(f'Label Element DType: {type(train_labels[0])}')\n",
    "print('**Shapes:**')\n",
    "print('Train Data:')\n",
    "print(f'Images: {train_images.shape}')\n",
    "print(f'Labels: {train_labels.shape}')\n",
    "print('Test Data:')  # the text images should be a random sample of the overall test set, and hence should have the same type, shape and image-size as the overall train set\n",
    "print(f'Images: {test_images.shape}')\n",
    "print(f'Labels: {test_labels.shape}')\n",
    "print('Image Data Range:')\n",
    "print(f'Min: {train_images.min()}')\n",
    "print(f'Max: {train_images.max()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess the data\n",
    "train_images = train_images.astype('float32') / 255.0\n",
    "test_images = test_images.astype('float32') / 255.0\n",
    "\n",
    "# Split the data into training and validation sets\n",
    "train_images, val_images, train_labels, val_labels = train_test_split(train_images, train_labels, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define and Train Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "750/750 [==============================] - 2s 2ms/step - loss: 0.5342 - accuracy: 0.8134 - val_loss: 0.4075 - val_accuracy: 0.8541\n",
      "Epoch 2/5\n",
      "750/750 [==============================] - 1s 2ms/step - loss: 0.3859 - accuracy: 0.8601 - val_loss: 0.4757 - val_accuracy: 0.8217\n",
      "Epoch 3/5\n",
      "750/750 [==============================] - 1s 2ms/step - loss: 0.3429 - accuracy: 0.8750 - val_loss: 0.3465 - val_accuracy: 0.8764\n",
      "Epoch 4/5\n",
      "750/750 [==============================] - 1s 2ms/step - loss: 0.3162 - accuracy: 0.8848 - val_loss: 0.3353 - val_accuracy: 0.8808\n",
      "Epoch 5/5\n",
      "750/750 [==============================] - 1s 2ms/step - loss: 0.2971 - accuracy: 0.8905 - val_loss: 0.3507 - val_accuracy: 0.8702\n"
     ]
    }
   ],
   "source": [
    "# Define the model\n",
    "model = keras.Sequential([\n",
    "    keras.layers.Flatten(input_shape=(28, 28)),\n",
    "    keras.layers.Dense(128, activation='relu'),\n",
    "    keras.layers.Dense(64, activation='relu'),\n",
    "    keras.layers.Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(train_images, train_labels, epochs=5, batch_size=64, validation_data=(val_images, val_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The neural network architecture used in the code is a simple feedforward neural network with three dense (fully connected) layers. Here's a breakdown of the layers:\n",
    "\n",
    "1. Input Layer (Flatten): This layer flattens the input images, which are initially 28x28 pixels, into a 1D array of size 784 (28 * 28). It serves as the input layer of the neural network.\n",
    "\n",
    "2. Hidden Layer 1 (Dense): This layer consists of 128 neurons and uses the ReLU activation function. Each neuron in this layer is fully connected to every neuron in the previous layer.\n",
    "\n",
    "3. Hidden Layer 2 (Dense): This layer consists of 64 neurons and also uses the ReLU activation function.\n",
    "\n",
    "4. Output Layer (Dense): This layer consists of 10 neurons, representing the 10 classes in the dataset (assuming it's a classification task). It uses the softmax activation function to output probabilities for each class."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate the model using the validation dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "375/375 [==============================] - 0s 657us/step\n",
      "Validation Metrics:\n",
      "Accuracy: 0.8701666666666666\n",
      "Precision: 0.8786148284981772\n",
      "Recall: 0.8701666666666666\n",
      "F1 Score: 0.8696236433659046\n"
     ]
    }
   ],
   "source": [
    "# Predict probabilities for each class\n",
    "val_probabilities = model.predict(val_images)\n",
    "\n",
    "# Get the predicted classes by selecting the class with the highest probability\n",
    "val_predictions = np.argmax(val_probabilities, axis=1)\n",
    "\n",
    "# Compute evaluation metrics\n",
    "accuracy = accuracy_score(val_labels, val_predictions)\n",
    "precision = precision_score(val_labels, val_predictions, average='weighted')\n",
    "recall = recall_score(val_labels, val_predictions, average='weighted')\n",
    "f1 = f1_score(val_labels, val_predictions, average='weighted')\n",
    "\n",
    "print(\"Validation Metrics:\")\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F1 Score:\", f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 0s 627us/step\n",
      "Test Metrics:\n",
      "Accuracy: 0.8618\n",
      "Precision: 0.869590896099919\n",
      "Recall: 0.8618\n",
      "F1 Score: 0.8605357734205682\n"
     ]
    }
   ],
   "source": [
    "# Predict probabilities for the test set\n",
    "test_probabilities = model.predict(test_images)\n",
    "\n",
    "# Get the predicted classes by selecting the class with the highest probability\n",
    "test_predictions = np.argmax(test_probabilities, axis=1)\n",
    "\n",
    "# Compute evaluation metrics\n",
    "test_accuracy = accuracy_score(test_labels, test_predictions)\n",
    "test_precision = precision_score(test_labels, test_predictions, average='weighted')\n",
    "test_recall = recall_score(test_labels, test_predictions, average='weighted')\n",
    "test_f1 = f1_score(test_labels, test_predictions, average='weighted')\n",
    "\n",
    "print(\"Test Metrics:\")\n",
    "print(\"Accuracy:\", test_accuracy)\n",
    "print(\"Precision:\", test_precision)\n",
    "print(\"Recall:\", test_recall)\n",
    "print(\"F1 Score:\", test_f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Conclusion:**\n",
    "\n",
    "- Accuracy: The model achieves an accuracy of 0.12 on the test set, indicating that only 12% of the test samples are correctly classified.\n",
    "\n",
    "- Precision: With a precision of 0.0144, the model's ability to correctly identify positive samples among all predicted positive instances is extremely low.\n",
    "- Recall: The recall score of 0.12 suggests that the model captures only 12% of all true positive samples.\n",
    "- F1 Score: At 0.0257, the F1 score, which balances precision and recall, also reflects the poor overall performance of the model.\n",
    "- Poor Generalization: The consistently low values across all metrics indicate that the model struggles to generalize well to unseen data.\n",
    "- Possible Improvements: To enhance model performance, strategies such as adjusting the model architecture, tuning hyperparameters, mitigating overfitting, and acquiring more diverse training data may be necessary."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Increase the precision for class '5'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 0s 691us/step\n",
      "Adjusted Precision for Class '5': 0.8632527418235443\n"
     ]
    }
   ],
   "source": [
    "# Original model predictions\n",
    "original_predictions = model.predict(test_images)\n",
    "\n",
    "# Define the class index for class '5' (assuming it's the sixth class, index 5)\n",
    "class_5_index = 5\n",
    "\n",
    "# Define the new threshold for class '5' (increasing the threshold)\n",
    "new_threshold = 0.95\n",
    "\n",
    "# Adjust the predictions\n",
    "adjusted_predictions = np.copy(original_predictions)\n",
    "adjusted_predictions[:, class_5_index] = (adjusted_predictions[:, class_5_index] >= new_threshold).astype(int)\n",
    "\n",
    "# Compute evaluation metrics\n",
    "adjusted_precision = precision_score(test_labels, np.argmax(adjusted_predictions, axis=1), average='weighted')\n",
    "\n",
    "print(\"Adjusted Precision for Class '5':\", adjusted_precision)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- This code adjusts the threshold for class '5' predictions to be higher, potentially leading to fewer instances classified as class '5' and consequently increasing the precision for this class without modifying the model or retraining it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Increase the recall for class '5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 0s 664us/step\n",
      "Adjusted Recall for Class '5': 0.8614\n"
     ]
    }
   ],
   "source": [
    "# Original model predictions\n",
    "original_predictions = model.predict(test_images)\n",
    "\n",
    "# Define the class index for class '5' (assuming it's the sixth class, index 5)\n",
    "class_5_index = 5\n",
    "\n",
    "# Define the new threshold for class '5' (lowering the threshold)\n",
    "new_threshold = 0.3\n",
    "\n",
    "# Adjust the predictions\n",
    "adjusted_predictions = np.copy(original_predictions)\n",
    "adjusted_predictions[:, class_5_index] = (adjusted_predictions[:, class_5_index] >= new_threshold).astype(int)\n",
    "\n",
    "# Compute evaluation metrics\n",
    "adjusted_recall = recall_score(test_labels, np.argmax(adjusted_predictions, axis=1), average='weighted')\n",
    "\n",
    "print(\"Adjusted Recall for Class '5':\", adjusted_recall)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- This code adjusts the threshold for class '5' predictions to be lower, potentially leading to more instances classified as class '5' and consequently increasing the recall for this class without modifying the model or retraining it."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow_cpu",
   "language": "python",
   "name": "tensorflow_cpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
